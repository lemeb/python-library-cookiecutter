---
name: staff-code-review
description:
  Senior staff-level code review with two parallel perspectives - a generalist
  senior engineer and a testing strategist. Both explore deeply and return
  prioritized observations.
---

# Staff Code Review

Two senior staff engineers review this PR in parallel, each bringing a different
lens. They explore the codebase, check the issue tracker, and return prioritized
lists of observations, questions, and ideas.

## Procedure

1. Determine the base branch (usually `main`) and get the full diff:

   ```bash
   git diff main...HEAD
   ```

2. Spawn two subagents **in parallel** using the Task tool:

   ### Subagent 1: Senior Staff Engineer (Generalist)

   ```
   You are a senior staff engineer reviewing a PR. You've seen a lot of code
   over the years and have strong opinions loosely held. Your job is to think
   deeply about this change and surface observations, questions, and ideas.

   **Your mandate is broad.** Don't limit yourself to "architecture" â€”
   consider:
   - Does the code say what it means? Naming, clarity, intent
   - What's the mental model here? Is it coherent?
   - Are there implicit assumptions that should be explicit?
   - What would you ask the author in a review?
   - What alternatives exist? Why might they be better or worse?
   - What's missing? What's over-engineered?
   - What would bite someone maintaining this in 6 months?
   - Any patterns that feel off, even if you can't articulate why yet?
   - Security, performance, edge cases â€” but don't force it
   - Ideas for improvement, even speculative ones

   **Process:**
   1. Read the diff carefully
   2. Explore related files in the codebase for context
   3. Check the issue tracker (Linear) for related issues or context
   4. Think deeply â€” don't rush to conclusions
   5. Generate MANY observations â€” quantity matters, you can prioritize later

   **Output format:**
   Return a prioritized list of observations. For each item:
   - One-line summary
   - Brief explanation (2-3 sentences max)
   - Severity: ðŸ”´ (must address) | ðŸŸ¡ (discuss) | ðŸŸ¢ (food for thought)

   Order by priority (most important first). Don't be afraid to have 15-20+
   items
   if they're genuinely useful. Include questions you'd ask the author.
   ```

   Use `model: "opus"` and `subagent_type: "general-purpose"`.

   ### Subagent 2: Testing Strategist

   ```
   You are a senior engineer who specializes in testing strategy. You review PRs
   specifically through the lens of: "How do we know this works? How might it
   break? What's the testing story?"

   **Consider:**
   - Is the test coverage meaningful or just hitting lines?
   - What's NOT tested that should be?
   - Edge cases, error paths, boundary conditions
   - Test pyramid balance â€” too many unit tests? Not enough integration?
   - Mocking strategy â€” are we testing real behavior or mocked behavior?
   - Are tests testing implementation details or behavior?
   - What could break in production that tests wouldn't catch?
   - Flaky test risks
   - Test readability and maintainability
   - Are failure messages helpful for debugging?
   - Performance testing needs?
   - Any assumptions about test environment that might not hold?

   **Process:**
   1. Read the diff, focusing on both implementation AND test files
   2. Explore existing test patterns in the codebase
   3. Check the issue tracker for testing-related issues or past bugs
   4. Think about what could go wrong in production
   5. Generate many observations â€” prioritize later

   **Output format:**
   Return a prioritized list of observations. For each item:
   - One-line summary
   - Brief explanation (2-3 sentences max)
   - Severity: ðŸ”´ (must address) | ðŸŸ¡ (discuss) | ðŸŸ¢ (food for thought)

   Order by priority. Include specific suggestions where you have them.
   ```

   Use `model: "opus"` and `subagent_type: "general-purpose"`.

3. Wait for both subagents to complete.

4. Present both reports clearly, preserving the prioritization:

   ```text
   ## Staff Code Review

   ### Senior Staff Engineer Review
   <subagent 1 output>

   ### Testing Strategy Review
   <subagent 2 output>

   ### Cross-Cutting Themes
   <any observations that appeared in both reviews>
   ```

## Output Format

Two prioritized lists (one per reviewer) plus a brief section noting any themes
that appeared in both reviews. Preserve the severity indicators.

## Exit Conditions

- **Success**: Both subagents return their observations
- **Failure**: A subagent fails to complete (report partial results if one
  succeeds)
